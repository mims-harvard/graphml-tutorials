{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Payal Chandak, on 20 June 2020\n",
    "<br> <br>\n",
    "Graphs in the real world, such as social networks, chemical molecules and biological knowledge graphs, are rich with information that cannot be found in individual entities. A method for learning graph representations or node classification would be extremely valuable. Unfortunately, the modern deep learning toolbox is designed for grids (ie. images) and simple sequences (ie. text). CNNs and RNNs cannot generalize to graphs that have arbitrary size, complex topological structures and no fixed node ordering. Graph neural networks (GNN) provide a powerful tool to learn representations from any arbitrary graph structure by leveraging local network neighborhoods. This tutorial aims to (1) introduce the concept of graph neural networks, (2) discuss the quatitative motivation behind different GNN architectures and (3) implement these architectures using the PyTorch Geometric library. \n",
    "<br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:16:50.313897Z",
     "start_time": "2020-06-21T13:16:13.726701Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.data import Data, GraphSAINTRandomWalkSampler\n",
    "from torch_geometric.datasets import Planetoid, Entities\n",
    "from torch_geometric.nn import GCNConv, RGCNConv, GATConv, SAGEConv, JumpingKnowledge, GINConv, DeepGraphInfomax\n",
    "\n",
    "torch.manual_seed(200620)\n",
    "np.random.seed(200620)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Graph Neural Network? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph neural networks have a somewhat universal architecture where forward propagation uses a 'neighborhood aggregation' technique. The model iteratively produces new feature representations for a given node by aggregating the current feature representations of its adjacent nodes’ (ie. neighbors) and the node itself. Here, an iteration is parametrized by a layer of the neural network. This means that the computational graph of the neural network is defined by the neighborhood of each node. And, each layer in the graph neural network can be thought of as a step where each node aggregates messages from its neighboring nodes, as visualized by Microsoft in this [video](https://www.youtube.com/watch?v=cWIeTMklzNg):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:16:50.550554Z",
     "start_time": "2020-06-21T13:16:50.317019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"890\"\n",
       "            height=\"500\"\n",
       "            src=\"https://www.youtube.com/embed/cWIeTMklzNg?start=70&end=460\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x12d14ad60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTubeVideo('cWIeTMklzNg', height=500, width=890, start=70, end=460)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a graph $\\mathcal{G} = (\\mathcal{V}, \\mathcal{E})$ described by an adjacency matrix $A$. The goal is to learn a function of node input features for node classification. The model takes as input a feature descriptions summarized by matrix $X$ which is $N \\times D$ ($N$: number of nodes, $D$: number of input features) and produces a node-level output $Z$ (a $N \\times C$ feature matrix, where $C$ is the number of classes per node). At the node level, each layer of the GNN is doing neighborhood aggregation to transform the node representation. At the graph level, every neural network layer can then be written as a non-linear function $f$: \n",
    "<br><br>$$H^{(l+1)}=f^{(l+1)}(H^{(l)},A)$$<br>\n",
    "with $H^{(0)}=X$ and $H^{(L)}=Z$, where L is the number of layers. Notice that each node started with an input vector of length $D$ and ended at a classification vector of length $C$, where $D$ need not equal $C$. This is possible because after doing neighborhood aggregation, $f$ applies a non-linear transformation to node representations using its parameters, a weight matrix $W$ and an activation $\\sigma$. The dimension of node representations will change from one layer to another when $W$ is not a square matrix. Note that each layer learns it's own parameters. The specific GNN architechtures then differ only in how $f(⋅,⋅)$ is chosen and parameterized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In recent years, many architectures of graph neural networks have been introduced. I will explore the quantitative motivations behind some of the most influential architectures in the field. I will also implement simple models using these architectures in PyTorch and evaluate them on the benchmark Cora dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:16:50.700215Z",
     "start_time": "2020-06-21T13:16:50.560524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this tutorial, we will use a standard citation dataset that is commonly used to benchmark GNN performance.\n",
      "The Cora dataset is a homogeneous, undirected graph where nodes are publications linked by citations.\n",
      "It contains:\n",
      "\t- 7 labels\n",
      "\t- 2708 nodes\n",
      "\t- 1208 training\n",
      "\t- 500 validation\n",
      "\t- 1000 testing\n"
     ]
    }
   ],
   "source": [
    "print('For this tutorial, we will use a standard citation dataset that is commonly used to benchmark GNN performance.')\n",
    "print('The Cora dataset is a homogeneous, undirected graph where nodes are publications linked by citations.')\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora', split='full')\n",
    "print('It contains:')\n",
    "graph = dataset[0]\n",
    "print('\\t- {:d} labels'.format(dataset.num_classes))\n",
    "print('\\t- {:d} nodes'.format(graph.num_nodes))\n",
    "print('\\t- {:d} training'.format(graph.train_mask.sum().item()))\n",
    "print('\\t- {:d} validation'.format(graph.val_mask.sum().item()))\n",
    "print('\\t- {:d} testing'.format(graph.test_mask.sum().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools for Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:16:50.710903Z",
     "start_time": "2020-06-21T13:16:50.704353Z"
    }
   },
   "outputs": [],
   "source": [
    "class Hyperparameters():\n",
    "    def __init__(self):\n",
    "        self.num_node_features = None\n",
    "        self.num_classes = None\n",
    "        self.lr = 0.005\n",
    "        self.w_decay = 5e-4   \n",
    "        self.dropout = 0.3\n",
    "        self.epochs = 200                \n",
    "        self.cuda = True                \n",
    "        self.device  =  None    \n",
    "\n",
    "args = Hyperparameters()\n",
    "args.num_node_features = graph.num_node_features\n",
    "args.num_classes = dataset.num_classes\n",
    "args.cuda = args.cuda and torch.cuda.is_available() \n",
    "if args.cuda:\n",
    "    args.device = torch.device('cuda:2') \n",
    "else:\n",
    "    args.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LearnGraph`class can train an arbitrary GNN on an arbitrary graph for node classification. By default, binary cross entropy loss and adam optimizer are used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:16:50.729337Z",
     "start_time": "2020-06-21T13:16:50.714000Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class LearnGraph(): \n",
    "    \n",
    "    def __init__(self, graph, model, args, criterion=None):\n",
    "        self.args = args\n",
    "        self.graph = graph.to(self.args.device)\n",
    "        self.model = model.to(self.args.device)\n",
    "        \n",
    "        if not criterion: \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        self.optim = torch.optim.Adam(self.model.parameters(), lr=self.args.lr, weight_decay=self.args.w_decay)\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.train_complete = False \n",
    "        \n",
    "    def learn(self) -> None:\n",
    "        # tracks training and validation loss over epochs\n",
    "        # can add early stopping mechanism by comparing losses\n",
    "        for epoch in range(self.args.epochs): \n",
    "            if self.train_complete: return\n",
    "            \n",
    "            tl = self.train_epoch()\n",
    "            self.train_loss.append(tl)\n",
    "            \n",
    "            vl = self.val()\n",
    "            self.val_loss.append(vl)\n",
    "                \n",
    "        self.train_complete = True\n",
    "        \n",
    "    def train_epoch(self) -> float:\n",
    "        # trains a single epoch (ie. one pass over the full graph) and updates the models parameters\n",
    "        # returns the loss\n",
    "        self.model.train()\n",
    "        labels = self.graph.y[self.graph.train_mask]\n",
    "        self.optim.zero_grad()\n",
    "        output = self.model.forward(self.graph) \n",
    "        loss = self.criterion(output[self.graph.train_mask], labels)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        return loss.data.item()\n",
    "    \n",
    "    def val(self) -> float:\n",
    "        # returns the validation loss \n",
    "        self.model.eval()\n",
    "        labels = self.graph.y[self.graph.val_mask]\n",
    "        output = self.model.forward(self.graph) \n",
    "        loss = self.criterion(output[self.graph.val_mask], labels)\n",
    "        return loss.data.item()\n",
    "    \n",
    "    def test(self) -> float: \n",
    "        # returns the test accuracy \n",
    "        if not self.train_complete: \n",
    "            self.learn()\n",
    "        self.model.eval()\n",
    "        labels = self.graph.y[self.graph.test_mask]    \n",
    "        _, pred = self.model.forward(self.graph).max(dim=1)\n",
    "        correct = float ( pred[self.graph.test_mask].eq(labels).sum().item() )\n",
    "        acc = correct / self.graph.test_mask.sum().item()\n",
    "        return acc\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[GCNConv](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv)** from Kipf and Welling: [Semi-Supervised Classification with Graph Convolutional Networks](https://arxiv.org/abs/1609.02907) (ICLR 2017)\n",
    "Also see [this blog by Kipf](http://tkipf.github.io/graph-convolutional-networks/) \n",
    "<br> <br> \n",
    "The basic propagation rule is $$f: \\sigma\\left(A H^{(l)} W^{(l)}\\right)$$  \n",
    "According to the adjacency matrix, we sum the feature vectors of all neighboring nodes but not the node itself. We fix this by enforcing self-loops: $\\hat{A} = A + I$\n",
    "Another limitation is that $\\hat{A}$ is not normalized, so multiplication with $\\hat{A}$ will completely change the scale of the feature vectors. Let $\\hat{D}$ be the diagonal node degree matrix. Simple normalization involves using $\\hat{D}^{-1} \\hat{A} \\text{ instead of } \\hat{A}$. In practice, we do symmetric normalization such that the final propagation rule is <br><br> \n",
    "$$f: \\sigma\\left(\\hat{D}^{-\\frac{1}{2}} \\hat{A} \\hat{D}^{-\\frac{1}{2}} H^{(l)} W^{(l)}\\right)$$<br> \n",
    "For a given node $i$ feature vector, where $ N_{i}$ is its neighborhood and $c_{i j}$ is a normalization constant for the edge $(i, j)$, the update is:  <br> <br> \n",
    "$$h_{i}^{(l+1)}=\\sigma\\ \\left(\\ \\sum_{j \\ \\in \\ N_{i}} \\frac{1}{c_{i j}} \\ h_{j}^{(l)} \\ W^{(l)}\\ \\right)$$<br> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:17:04.817428Z",
     "start_time": "2020-06-21T13:16:50.735049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.9%\n"
     ]
    }
   ],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(args.num_node_features, 64)\n",
    "        self.conv2 = GCNConv(64, args.num_classes)\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=args.dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, graph): \n",
    "        x, edge_index = graph.x, graph.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.transition(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "learner = LearnGraph(model=GNN(), graph=graph, args=args)\n",
    "acc = learner.test()\n",
    "print('Accuracy: {:.1%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relational Graph Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[RGCNConv](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.RGCNConv)** from Schlichtkrull *et al.*: [Modeling Relational Data with Graph Convolutional Networks](https://arxiv.org/abs/1703.06103) (ESWC 2018)\n",
    "<br> <br> \n",
    "'Knowledge' graphs have nodes connected by many different relationships. To capture many types of links in graphs, we can apply relation-specific transformations on incoming messages. For a specific node $i$, $\\mathcal{N}_{i}^{r}$ contains its neighbors connected by link $r$. $c_{i, r}$ is a normalization constant (such as $|\\mathcal{N}_{i}^{r}|$). \n",
    "<br> <br>  $$h_{i}^{(l+1)}=\\sigma\\left(\\ \\sum_{r \\ \\in \\ \\mathcal{R}} \\  \\sum_{j \\ \\in \\ \\mathcal{N}_{i}^{r}} \\frac{1}{c_{i, r}} \\ W_{r}^{(l)}  h_{j}^{(l)}+W_{0}^{(l)} h_{i}^{(l)}\\right)$$<br> \n",
    "The parameters of the network grow rapidly with the number of relations in the graph. We need regularlization to prevent overfitting on rare relations. Using basis decompostion, each $W_{r}^{(l)}$ is defined as a linear combination of basis vectors $V_{b}^{(l)} \\in \\mathbb{R}^{d^{(l+1)} \\times d^{(l)}}$, the space of $W_{r}^{(l)}$. Only the coefficients $a_{r b}^{(l)}$ depend on $r$. This method alleviates overfitting by creating weight sharing across frequent and rare relations. \n",
    "<br> <br> $$W_{r}^{(l)}=\\sum_{b=1}^{B} a_{r b}^{(l)} V_{b}^{(l)}$$<br> \n",
    "Since R-GCN is applied to heterogenous graphs, we will use the MUTAG graph instead of Cora. RGCN auto-generates unique embeddings as input features for nodes if no features are provided, as in MUTAG. Minor changes made to `LearnGraph`to accomodate MUTAG. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:18:06.863835Z",
     "start_time": "2020-06-21T13:17:04.821768Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.1%\n"
     ]
    }
   ],
   "source": [
    "mutag_dataset = Entities(root='/tmp/MUTAG', name='MUTAG')\n",
    "mutag_graph = mutag_dataset[0]\n",
    "\n",
    "class LearnMUTAG(): \n",
    "    \n",
    "    def __init__(self, graph, model, args, criterion=None):\n",
    "        self.args = args\n",
    "        self.graph = graph.to(self.args.device)\n",
    "        self.model = model.to(self.args.device)\n",
    "        \n",
    "        if not criterion: \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        self.optim = torch.optim.Adam(self.model.parameters(), lr=self.args.lr, weight_decay=self.args.w_decay)\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.train_complete = False \n",
    "        \n",
    "    def learn(self) -> None:\n",
    "        for epoch in range(self.args.epochs): \n",
    "            if self.train_complete: return\n",
    "            tl = self.train_epoch()\n",
    "            self.train_loss.append(tl)\n",
    "        self.train_complete = True\n",
    "        \n",
    "    def train_epoch(self) -> float:\n",
    "        self.model.train()\n",
    "        labels = self.graph.train_y\n",
    "        self.optim.zero_grad()\n",
    "        output = self.model.forward(self.graph) \n",
    "        loss = self.criterion(output[self.graph.train_idx], labels)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        return loss.data.item()\n",
    "    \n",
    "    def test(self) -> float: \n",
    "        # returns the test accuracy \n",
    "        if not self.train_complete: \n",
    "            self.learn()\n",
    "        self.model.eval()\n",
    "        labels = self.graph.test_y\n",
    "        _, pred = self.model.forward(self.graph).max(dim=1)\n",
    "        correct = float ( pred[self.graph.test_idx].eq(labels).sum().item() )\n",
    "        acc = correct / len(self.graph.test_idx)\n",
    "        return acc\n",
    "    \n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = RGCNConv(mutag_graph.num_nodes, 16, mutag_dataset.num_relations, num_bases=30)\n",
    "        self.conv2 = RGCNConv(16, mutag_dataset.num_classes, mutag_dataset.num_relations, num_bases=30)\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=args.dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, graph): \n",
    "        x, edge_index, edge_type = graph.x, graph.edge_index, graph.edge_type\n",
    "        x = self.conv1(x, edge_index, edge_type)\n",
    "        x = self.transition(x)\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return x\n",
    "\n",
    "learner = LearnMUTAG(model=GNN(), graph=mutag_graph, args=args)\n",
    "acc = learner.test()\n",
    "print('Accuracy: {:.1%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Attention Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[GATConv](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GATConv)** from Veličković *et al.*: [Graph Attention Networks](https://arxiv.org/abs/1710.10903) (ICLR 2018)\n",
    "<br> <br> \n",
    "GATConv is inspired by the use of self-attention (Google transformer) which has achieved SOTA performance in NLP. The idea is that nodes can 'attend' over their neighbors and select the direction from which they recieve information. For a single layer, where nodes go from $F$ to $F^{\\prime}$ features, the following steps are applied: \n",
    "\n",
    "1. Linear transformation of input features using a weight matrix, $\\mathbf{W} \\in \\mathbb{R}^{F^{\\prime} \\times F}$\n",
    "\n",
    "2. Compute attention coefficients $e_{i j} \\in \\mathbb{R}$ for each node pair $(i, j)$ using a shared attention mechanism $a$. Here this mechanism is a single-layer feedforward network network with a the parameter vector, $\\overrightarrow{\\mathbf{a}} \\in \\mathbb{R}^{2 F^{\\prime}}$\n",
    "<br> <br>$$e_{i j}=a\\left(\\mathbf{W} \\vec{h}_{i}, \\mathbf{W} \\vec{h}_{j}\\right) = \\text{LeakyReLU}\\left(\\overrightarrow{\\mathbf{a}}^{T}\\left[\\mathbf{W} \\vec{h}_{i} \\| \\mathbf{W} \\vec{h}_{j}\\right]\\right)$$ <br>\n",
    "\n",
    "3. Normalize attention coefficients across nodes: $\\alpha_{i j}=\\operatorname{softmax}_{j}\\left(e_{i j}\\right)$ \n",
    "\n",
    "4. Compute output features as a linear combination of input features corresponding to their normalized attention coefficients \n",
    "<br> <br> $$\\vec{h}_{i}^{\\prime}=\\sigma\\left(\\sum_{j \\in \\mathcal{N}_{i}} \\alpha_{i j} \\mathbf{W} \\vec{h}_{j}\\right)$$ <br>\n",
    "5. This process can be stabilized using multi-head attention, which concatenates/averages multiple indepedently computed output features from independent attention layers <br> <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:18:25.584282Z",
     "start_time": "2020-06-21T13:18:06.869480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.2%\n"
     ]
    }
   ],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GATConv(args.num_node_features, 8, heads=8)\n",
    "        self.conv2 = GATConv(64, args.num_classes, heads=1)\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=args.dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, graph): \n",
    "        x, edge_index = graph.x, graph.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.transition(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "learner = LearnGraph(model=GNN(), graph=graph, args=args)\n",
    "acc = learner.test()\n",
    "print('Accuracy: {:.1%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphSAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[SAGEConv](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.SAGEConv)** from Hamilton *et al.*: [Inductive Representation Learning on Large Graphs](https://arxiv.org/abs/1706.02216) (NIPS 2017)\n",
    "<br> <br> \n",
    "GraphSAGE generalizes GCN to use trainable aggregation functions beyond simple convolutions. For a given layer $(l+1)$, at each node $i$, the embeddings $h_{j}^{(l)}$ for all nodes $j$ in its neighborhood $\\mathcal{N}(i)$ are combined into a single vector $h^{(l+1)}_{\\mathcal{N}(i)}$ using an aggregation function. Aggregating the neighborhood separately from the node itself implictly adds skip connections across layers.\n",
    "<br> <br> $$\\mathbf{h}_{\\mathcal{N}(i)}^{(l+1)} = \\operatorname{AGGREGATE}_{(l+1)}\\left(\\left\\{\\mathbf{h}_{j}^{(l)}, \\forall j \\in \\mathcal{N}(i)\\right\\}\\right)$$  <br>\n",
    "Aggregation functions can include mean (~traditional GCN), LSTM and Pooling. In max pooling, each neighbor vector is fed through a single-layer neural network and then an elementwise max-pooling operation is applied. Max pooling implicitly selects the important nodes, much like Graph Attention Networks.\n",
    "<br> <br> $$\\mathrm{AGGREGATE}_{(l+1)}^{\\mathrm{pool}}=\\max \\left(\\left\\{\\sigma\\left(\\mathbf{W}_{\\mathrm{pool}} \\ \\mathbf{h}_{j}^{(l+1)}+\\mathbf{b}\\right), \\forall j \\in \\mathcal{N}(i)\\right\\}\\right)$$ <br>\n",
    "The final step is to concatenate the node's current representation $h^{(l)}_{i}$ with the aggregated neighborhood vector $h^{(l+1)}_{\\mathcal{N}(i)}$. This concatenated vector is fed through a single-layer neural network to calculate the output representation $h^{(l+1)}_{i}$\n",
    "<br> <br> $$\\mathbf{h}_{i}^{(l+1)} = \\sigma \\left(W_{(l+1)} \\left[\\ h^{(l)}_{i} \\  \\| \\  h^{(l+1)}_{\\mathcal{N}(i)}\\ \\right] \\right)$$ <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:19:51.863950Z",
     "start_time": "2020-06-21T13:18:25.600366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 85.1%\n"
     ]
    }
   ],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = SAGEConv(args.num_node_features, 64, normalize=True)\n",
    "        self.conv1.aggr = 'max'\n",
    "        self.conv2 = SAGEConv(64, args.num_classes,  normalize=True)\n",
    "        self.conv2.aggr = 'max'\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=args.dropout)\n",
    "        )\n",
    "        print()\n",
    "\n",
    "    def forward(self, graph): \n",
    "        x, edge_index = graph.x, graph.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.transition(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "learner = LearnGraph(model=GNN(), graph=graph, args=args)\n",
    "acc = learner.test()\n",
    "print('Accuracy: {:.1%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jumping Knowledge Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Jumping Knowledge](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.models.JumpingKnowledge)** from Xu *et al.*: [Representation Learning on Graphs with Jumping Knowledge Networks](https://arxiv.org/abs/1806.03536) (ICML 2018)\n",
    "<br> <br>\n",
    "Many aggregation based models achieve best performance with 2 layer networks. After that, performance degrades despite theoretically greater access to information and even after adding residual connections. In biological networks, the majority of the nodes have few connections, whereas some nodes are hubs. In the same graph, the same number of GNN layers an lead to very different effects for different nodes. \n",
    "<br> <br>\n",
    "Unlike GAT or GraphSAGE which select the direction of expansion, Jumping Knowledge operates on the locality of expansion. This model proposes two architectural changes – jump connections and a subsequent selective but adaptive aggregation mechanism. As in common neighborhood aggregation networks, each layer increases the size of the influence distribution by aggregating neighborhoods from the previous layer. In the last JK layer, for each node, we select from all of those intermediate representations. If this is done independently for each node, then the model can adapt the effective neighborhood size for each node as needed, resulting in exactly the desired adaptivity. The layer aggregation mechanisms can include concatenation, max pooling, and lstm attention. \n",
    "<br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:20:32.835990Z",
     "start_time": "2020-06-21T13:19:51.866615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.7%\n"
     ]
    }
   ],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(args.num_node_features, 64)\n",
    "        self.convx= GCNConv(64, 64)\n",
    "        self.jk = JumpingKnowledge(mode='max')\n",
    "        self.final = nn.Linear(64, args.num_classes)\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=args.dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, graph): \n",
    "        x, edge_index = graph.x, graph.edge_index\n",
    "        xs = []\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.transition(x)\n",
    "        xs.append(x)\n",
    "        for _ in range(5): \n",
    "            x = self.convx(x, edge_index)\n",
    "            x = self.transition(x)\n",
    "            xs.append(x)\n",
    "        x = self.jk(xs)\n",
    "        x = self.final(x)\n",
    "        return x\n",
    "\n",
    "learner = LearnGraph(model=GNN(), graph=graph, args=args)\n",
    "acc = learner.test()\n",
    "print('Accuracy: {:.1%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Isomorphism Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[GINConv](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GINConv)** from Xu *et al.*: [How Powerful are Graph Neural Networks?](https://arxiv.org/abs/1810.00826) (ICLR 2019)\n",
    "<br> <br>\n",
    "This work aimed to increase the expressive power of GNNs. The Weisfeiler-Lehman (WL) test for graph isomorphism uses injective node aggregation to distinguish graphs from each other. They show that GNNs can be as powerful as the WL test in distinguishing graph structures if the GNN’s aggregation scheme is highly expressive and can model injective (one-one) functions. A nodes neighbors are defined as a multiset, i.e., a set with possibly repeating elements. Sum aggregators can represent injective (and universal) functions over multisets. On the other hand, mean or max aggregators (used in GraphSAGE or GCN) are not injective multiset functions. The Graph Isomorphism Network uses a multi-layer perceptron to do neighborhood aggregation. Note that this argument holds under their key assumption that \"node input features are from a countable universe\" which is a very simplistic view of input features. \n",
    "<br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:22:01.715535Z",
     "start_time": "2020-06-21T13:20:32.842442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.3%\n"
     ]
    }
   ],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(GNN, self).__init__()\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=args.dropout)\n",
    "        )\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Linear(args.num_node_features, 256), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(256, 64), \n",
    "        )\n",
    "        self.conv1 = GINConv(self.mlp1)\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Linear(64, 16), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, args.num_classes), \n",
    "        )\n",
    "        self.conv2= GINConv(self.mlp2)\n",
    "        \n",
    "        \n",
    "    def forward(self, graph): \n",
    "        x, edge_index = graph.x, graph.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.transition(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "        \n",
    "learner = LearnGraph(model=GNN(), graph=graph, args=args)\n",
    "acc = learner.test()\n",
    "print('Accuracy: {:.1%}'.format(acc))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Graph Infomax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Deep Graph Infomax](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.models.DeepGraphInfomax)** from Veličković *et al.*: [Deep Graph Infomax](https://arxiv.org/abs/1809.10341) (ICLR 2019)\n",
    "<br> <br>\n",
    "Unsupervised embeddings have traditionally been trained with random-walk objectives, which can over-emphasize proximity information at the expense of structural information. Since encoders already enforce an inductive bias that neighboring nodes have similar representations, it is unclear whether random-walk objectives actually provide any useful signal. Deep graph infomax is an alternative objective for unsupervised graph learning that is based upon mutual information. \n",
    "<br> <br>\n",
    "The DGI objective seeks to maximize local mutual information by obtaining obtain node (i.e., local) representations that capture the global information content of the entire graph. As all of the derived patch representations are driven to preserve mutual information with the global graph summary, this allows for discovering and preserving similarities on the patch-level. This is useful because distant nodes with similar structural roles are known to be a strong predictor for many node classification tasks.\n",
    "<br> <br>\n",
    "The DGI model is defined by an encoder $\\mathcal{E}$, discriminator $\\mathcal{D}$, readout function $\\mathcal{R}$ and corruption function $\\mathcal{C}$. The GNN encoder outputs node representations $h_{i}$. The readout function gives a summary vector, $\\vec{s}$, which is the global graph representation. The discriminator takes the graph summary $s$ and a node $h_{i}$ and assigns a co-occurence probablity $\\mathcal{D}(h_{i}, s)$ to the pair. For negative samples, the graph structured is randomly changed using $\\mathcal{C}$, and the same process is repeated. The objective is structured in binary cross entropy form: \n",
    "<br> <br>$$\\mathcal{L}=\\frac{1}{N+M}\\left(\\sum_{i=1}^{N} \\mathbb{E}_{(\\mathbf{X}, \\mathbf{A})}\\left[\\log \\mathcal{D}\\left(\\vec{h}_{i}, \\vec{s}\\right)\\right]+\\sum_{j=1}^{M} \\mathbb{E}_{(\\widetilde{\\mathbf{X}}, \\widetilde{\\mathbf{A}})}\\left[\\log \\left(1-\\mathcal{D}\\left(\\overrightarrow{\\widetilde{h}_{j}}, \\vec{s}\\right)\\right)\\right]\\right)$$ <br>\n",
    "For supervised learning, we can incorporate the DGI objective in an intermediate, hidden layer in conjunction with the traditional BCE loss at the final layer.<br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:22:22.502344Z",
     "start_time": "2020-06-21T13:22:01.717780Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.7%\n"
     ]
    }
   ],
   "source": [
    "class LearnDeepGraphInfomax(): \n",
    "    \n",
    "    def __init__(self, graph, enc_dgi, enc_cls, args, criterion=None): \n",
    "        self.args = args\n",
    "        self.graph = graph.to(self.args.device)\n",
    "        \n",
    "        self.dgi_model = DeepGraphInfomax(enc_dgi.hidden_ch, enc_dgi, enc_dgi.summary, enc_dgi.corruption)\n",
    "        self.dgi_model = self.dgi_model.to(self.args.device)\n",
    "        \n",
    "        self.cls_model = enc_cls.to(self.args.device)\n",
    "        \n",
    "        if not criterion: \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        parameters = [*self.dgi_model.parameters()] + [*self.cls_model.parameters()]\n",
    "        self.optim = torch.optim.Adam(parameters, lr=self.args.lr, weight_decay=self.args.w_decay)\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.train_complete = False\n",
    "        \n",
    "    def learn(self) -> None: \n",
    "        for epoch in range(self.args.epochs): \n",
    "            if self.train_complete: return\n",
    "            \n",
    "            tl = self.train_epoch()\n",
    "            self.train_loss.append(tl)\n",
    "            \n",
    "            vl = self.val()\n",
    "            self.val_loss.append(vl)\n",
    "                \n",
    "        self.train_complete = True   \n",
    "        \n",
    "    def train_epoch(self) -> float:\n",
    "        self.dgi_model.train()\n",
    "        self.cls_model.train()\n",
    "        labels = self.graph.y[self.graph.train_mask]\n",
    "        self.optim.zero_grad()\n",
    "        pos_z, neg_z, summary = self.dgi_model.forward(x=self.graph.x, edge_index=self.graph.edge_index)\n",
    "        output = self.cls_model.forward(pos_z, self.graph.edge_index)\n",
    "        loss = self.dgi_model.loss(pos_z, neg_z, summary) + self.criterion(output[self.graph.train_mask], labels)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        return loss.data.item()\n",
    "    \n",
    "    def val(self) -> float: \n",
    "        self.dgi_model.eval()\n",
    "        self.cls_model.eval()\n",
    "        labels = self.graph.y[self.graph.val_mask]\n",
    "        pos_z, neg_z, summary = self.dgi_model.forward(self.graph.x, self.graph.edge_index)\n",
    "        output = self.cls_model.forward(pos_z, self.graph.edge_index)\n",
    "        loss = self.dgi_model.loss(pos_z, neg_z, summary) + self.criterion(output[self.graph.val_mask], labels)\n",
    "        return loss.data.item()\n",
    "    \n",
    "    def test(self) -> float: \n",
    "        if not self.train_complete: \n",
    "            self.learn()\n",
    "        self.dgi_model.eval()\n",
    "        self.cls_model.eval()\n",
    "        labels = self.graph.y[self.graph.test_mask]   \n",
    "        pos_z, neg_z, summary = self.dgi_model.forward(self.graph.x, self.graph.edge_index)\n",
    "        _, pred = self.cls_model.forward(pos_z, self.graph.edge_index).max(dim=1)\n",
    "        correct = float ( pred[self.graph.test_mask].eq(labels).sum().item() )\n",
    "        acc = correct / self.graph.test_mask.sum().item()\n",
    "        return acc\n",
    "\n",
    "\n",
    "class Encoder_DGI(torch.nn.Module):\n",
    "    def __init__(self, hidden_ch=64): \n",
    "        super(Encoder_DGI, self).__init__()\n",
    "        self.hidden_ch = hidden_ch\n",
    "        self.conv = GCNConv(args.num_node_features, hidden_ch)\n",
    "        self.activation = nn.PReLU()\n",
    "        \n",
    "    def corruption(self, x, edge_index): \n",
    "        # corrupted features are obtained by row-wise shuffling of the original features \n",
    "        # corrupted graph consists of the same nodes but located in different places \n",
    "        return x[torch.randperm(x.size(0))], edge_index\n",
    "        \n",
    "    def summary(self, z, *args, **kwargs): \n",
    "        return torch.sigmoid(z.mean(dim=0))\n",
    "\n",
    "    def forward(self, x, edge_index): \n",
    "        x = self.conv(x, edge_index)\n",
    "        x = self.activation(x)\n",
    "        return x \n",
    "\n",
    "\n",
    "class Encoder_CLS(torch.nn.Module):\n",
    "    def __init__(self, hidden_ch=64): \n",
    "        super(Encoder_CLS, self).__init__()\n",
    "        self.conv = GCNConv(hidden_ch, args.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index): \n",
    "        return self.conv(x, edge_index)\n",
    "\n",
    "\n",
    "learner = LearnDeepGraphInfomax(enc_dgi=Encoder_DGI(), enc_cls=Encoder_CLS(), graph=graph, args=args)\n",
    "acc = learner.test()\n",
    "print('Accuracy: {:.1%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphSAINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[GraphSAINT](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.GraphSAINTSampler)** from Zeng *et al.*: [GraphSAINT: Graph Sampling Based Inductive Learning Method](https://arxiv.org/abs/1907.04931) (ICLR 2020)\n",
    "<br> <br> \n",
    "As the GNN becomes deeper, training time can grow exponentially due to \"neighbor explosion\". GraphSAINT samples the training graph first and then builds a full GNN on the subgraph. Intuitively, nodes of higher influence on each other should have higher probability to form a subgraph. This enables the sampled nodes to “support” each other without going outside the minibatch. Unfortunately, such strategy results in non-identical node sampling probability, and introduces bias in the minibatch estimator. GraphSAINT employs normalization techniques so that the feature learning does not give preference to nodes more frequently sampled. The GraphSAINT sampler can be applied to any graph irrespective of the GNN being trained on that graph.\n",
    "<br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:22:27.784728Z",
     "start_time": "2020-06-21T13:22:22.504838Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute GraphSAINT normalization: : 151317it [00:00, 641410.73it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.6%\n"
     ]
    }
   ],
   "source": [
    "class LearnGraphSAINT(): \n",
    "    \n",
    "    def __init__(self, graph, model, args, criterion=None):\n",
    "        self.args = args\n",
    "        self.graph = graph.to(self.args.device)\n",
    "        self.model = model.to(self.args.device)\n",
    "        \n",
    "        self.loader =  GraphSAINTRandomWalkSampler(self.graph, batch_size=100, walk_length=2, num_steps=self.args.epochs)\n",
    "        \n",
    "        if not criterion: \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        self.optim = torch.optim.Adam(self.model.parameters(), lr=self.args.lr, weight_decay=self.args.w_decay)\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.train_complete = False \n",
    "        \n",
    "    def learn(self) -> None: \n",
    "        \n",
    "        for epoch, batch in enumerate(self.loader): \n",
    "            if self.train_complete: return\n",
    "        \n",
    "            tl = self.train_batch(batch)\n",
    "            self.train_loss.append(tl)\n",
    "            \n",
    "            vl = self.val()\n",
    "            self.val_loss.append(vl)\n",
    "                \n",
    "        self.train_complete = True\n",
    "        \n",
    "    def train_batch(self, batch) -> float:\n",
    "        self.model.train()\n",
    "        labels = batch.y[batch.train_mask]\n",
    "        self.optim.zero_grad()\n",
    "        output = self.model.forward(batch) \n",
    "        loss = self.criterion(output[batch.train_mask], labels)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        return loss.data.item()\n",
    "    \n",
    "    def val(self) -> float: \n",
    "        self.model.eval()\n",
    "        labels = self.graph.y[self.graph.val_mask]\n",
    "        output = self.model.forward(self.graph) \n",
    "        loss = self.criterion(output[self.graph.val_mask], labels)\n",
    "        return loss.data.item()\n",
    "    \n",
    "    def test(self) -> float: \n",
    "        if not self.train_complete: \n",
    "            self.learn()\n",
    "        self.model.eval()\n",
    "        labels = self.graph.y[self.graph.test_mask]    \n",
    "        _, pred = self.model.forward(self.graph).max(dim=1)\n",
    "        correct = float ( pred[self.graph.test_mask].eq(labels).sum().item() )\n",
    "        acc = correct / self.graph.test_mask.sum().item()\n",
    "        return acc\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(args.num_node_features, 64)\n",
    "        self.conv2 = GCNConv(64, args.num_classes)\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=args.dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, graph): \n",
    "        x, edge_index = graph.x, graph.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.transition(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "learner = LearnGraphSAINT(model=GNN(), graph=graph, args=args)\n",
    "acc = learner.test()\n",
    "print('Accuracy: {:.1%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More...\n",
    "* PyTorch Geometric [GitHub](https://github.com/rusty1s/pytorch_geometric) – even more architectures and examples\n",
    "* Customizing GNNs – using the [Message Passing base class](https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html) in PyTorch Geometric\n",
    "* [Deep Graph Library](https://www.dgl.ai) – an alternative to PyTorch Geometric"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "344.0625px",
    "left": "941.9701538085938px",
    "top": "72.25000762939453px",
    "width": "224.15760803222656px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
